{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.util import distributionPreservingDownsample\n",
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.environ['OPENAI_API_KEY']\n",
    "openai.api_key = apikey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file with 8210 rows, kept 6462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>deleted</th>\n",
       "      <th>display_name</th>\n",
       "      <th>text</th>\n",
       "      <th>spam_flag</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8741</td>\n",
       "      <td>False</td>\n",
       "      <td>Deb Musta Ginkel</td>\n",
       "      <td>I have very many  fond memories growing up wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8740</td>\n",
       "      <td>True</td>\n",
       "      <td>ROSE</td>\n",
       "      <td>I NEED AN URGENT LOVE SPELL CASTER TO BRING BA...</td>\n",
       "      <td>True</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8738</td>\n",
       "      <td>False</td>\n",
       "      <td>Joyce Ann Mosimann</td>\n",
       "      <td>Dear Janet and Bruce.  Gary and I are sending ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8737</td>\n",
       "      <td>False</td>\n",
       "      <td>Ed</td>\n",
       "      <td>Where is my friends buried I went by our lady ...</td>\n",
       "      <td>False</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8736</td>\n",
       "      <td>True</td>\n",
       "      <td>Ramone</td>\n",
       "      <td>I had the opportunity to meet and sit withe ma...</td>\n",
       "      <td>True</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  deleted        display_name   \n",
       "0  8741    False    Deb Musta Ginkel  \\\n",
       "1  8740     True                ROSE   \n",
       "3  8738    False  Joyce Ann Mosimann   \n",
       "4  8737    False                  Ed   \n",
       "5  8736     True              Ramone   \n",
       "\n",
       "                                                text  spam_flag  spam  \n",
       "0  I have very many  fond memories growing up wit...      False   ham  \n",
       "1  I NEED AN URGENT LOVE SPELL CASTER TO BRING BA...       True  spam  \n",
       "3  Dear Janet and Bruce.  Gary and I are sending ...      False   ham  \n",
       "4  Where is my friends buried I went by our lady ...      False   ham  \n",
       "5  I had the opportunity to meet and sit withe ma...       True  spam  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCommentsDf = pd.read_json('data/comments.json')[['id', 'deleted', 'display_name', 'text', 'spam_flag']]\n",
    "df = allCommentsDf[allCommentsDf['text'].str.len() < 2000]\n",
    "df = df.drop_duplicates(subset=['text'])\n",
    "df['spam'] = ['ham' if x == False else 'spam' for x in df['spam_flag']]\n",
    "\n",
    "print(\"Loaded data file with {} rows, kept {}\".format(len(allCommentsDf), len(df)))\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample to smaller dataset\n",
    "\n",
    "When first training the model, it can be helpful to work with a smaller dataset.  This distributionPreservingDownsample will select a random subset of the dataframe, with the same ratio of spam/ham in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled 6462 -> 500\n",
      "Ratio of True / False in original dataset: 0.14035902197462086 / 0.8596409780253791\n",
      "Ratio of True / False in downsampled dataset: 0.14 / 0.86\n"
     ]
    }
   ],
   "source": [
    "downsampled = distributionPreservingDownsample(df, 'spam_flag', 500)\n",
    "print(\"Downsampled {} -> {}\".format(len(df),len(downsampled)))\n",
    "print(\"Ratio of True / False in original dataset: {} / {}\".format(len(df[df['spam_flag'] == True]) / len(df),len(df[df['spam_flag'] == False]) / len(df)))\n",
    "print(\"Ratio of True / False in downsampled dataset: {} / {}\".format(len(downsampled[downsampled['spam_flag'] == True]) / len(downsampled),len(downsampled[downsampled['spam_flag'] == False]) / len(downsampled)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build prompt->completion data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>Save Your Marriage from divorce today. Get You...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>GREAT LOVE SPELL CASTER DR PETER THAT HELP ME ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>Hello friend, I recommend this great powerful ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>\\nDon't by any chance trust these online inves...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>CRYPTOCURRENCY RECOVERY/ BTC RECOVERY\\n\\nI had...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt completion\n",
       "3098  Save Your Marriage from divorce today. Get You...       spam\n",
       "2251  GREAT LOVE SPELL CASTER DR PETER THAT HELP ME ...       spam\n",
       "2633  Hello friend, I recommend this great powerful ...       spam\n",
       "2501  \\nDon't by any chance trust these online inves...       spam\n",
       "910   CRYPTOCURRENCY RECOVERY/ BTC RECOVERY\\n\\nI had...       spam"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfToUse = df\n",
    "# jsonlFilename = \"comments_full\"\n",
    "dfToUse = downsampled\n",
    "jsonlFilename = \"comments_small\"\n",
    "train = dfToUse[['text', 'spam']].copy()\n",
    "train.rename(columns={'spam': 'completion', 'text': 'prompt'}, inplace=True)\n",
    "train.to_json(f\"data/{jsonlFilename}.jsonl\", orient='records', lines=True)\n",
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use OpenAI CLI data cleaner to prepare train/validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 500 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified files to `data/comments_small_prepared_train.jsonl` and `data/comments_small_prepared_valid.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"data/comments_small_prepared_train.jsonl\" -v \"data/comments_small_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" ham\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"am\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 14.33 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f data/{jsonlFilename}.jsonl -q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kick off a Fine-Tune training request\n",
    "Buckle up, this will take a while.  I'm currently seeing it take 2-4 hours for OpenAI to start my training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"ada\"\n",
    "\n",
    "trainFile = f\"data/{jsonlFilename}_prepared_train.jsonl\"\n",
    "validateFile = f\"data/{jsonlFilename}_prepared_valid.jsonl\"\n",
    "\n",
    "command = f\"OPENAI_API_KEY={apikey} openai api fine_tunes.create -t {trainFile} -v {validateFile} -m {model} --compute_classification_metrics --classification_positive_class \\\" ham\\\"\"\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the fine tune id from the output of the previous command\n",
    "ftId = 'ft-1AjDPOyOMzWc6ve1htacVUsg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-16 23:46:22] Created fine-tune: ft-1AjDPOyOMzWc6ve1htacVUsg\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-1AjDPOyOMzWc6ve1htacVUsg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "command = f\"OPENAI_API_KEY={apikey} openai api fine_tunes.follow -i {ftId}\"\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all created fine-tunes\n",
    "command = f\"OPENAI_API_KEY={apikey} openai api fine_tunes.list\"\n",
    "!{command}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out the trained model\n",
    "Spot check a couple out-of-sample comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSpam(comment):\n",
    "    res = openai.Completion.create(\n",
    "        model=os.environ['FINE_TUNE_MODEL_ID'],\n",
    "        prompt=comment[:1500] + \"\\n\\n###\\n\\n\",\n",
    "        max_tokens=1,\n",
    "        temperature=0,\n",
    "        logprobs=2)\n",
    "    label = res.choices[0].text\n",
    "    if (label == \" spam\"):\n",
    "        return True\n",
    "    elif (label == \" ham\"):\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Error, unexpected model output: {}\".format(label))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamPrompt = \"I am so Happy we were able to share a few more memories at Grandma and Grandma’s house last summer. You are all in my heart. Thank you cousin Connie for the LOVE\"\n",
    "spamPrompt = \"Hello everyone my names are ALEX JACKSON from the UK, I want to use this golden medium to appreciate Doctor Abdul a great spell caster for helping me retrieving back my relationship with my ex lover when he ended and turned back on me for quite a long time now (6 months ago). He performed a spell for me and within 48 hours after the spell had been cast I received a text from my ex saying that he is sorry for the pains and tears that he had caused me and that he will not do such a thing to me again in his life. I was surprised but later accepted him back again. Anyone that is in the same line of problem or different one that wants to contact a spell caster should happily contact Doctor Abdul now on this email address.doctorabdulspellcaster@gmail.com or message him through his Whatsapp +2348108728256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamPrompt is spam: False\n",
      "spamPrompt is spam: True\n"
     ]
    }
   ],
   "source": [
    "print(\"hamPrompt is spam: {}\".format(isSpam(hamPrompt)))\n",
    "print(\"spamPrompt is spam: {}\".format(isSpam(spamPrompt)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
